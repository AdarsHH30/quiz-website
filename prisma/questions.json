[
  {
    "text": "Which of the following best describes the first wave of AI?",
    "options": [
      {
        "text": "Machine Learning",
        "isCorrect": false
      },
      {
        "text": "Rule-based systems",
        "isCorrect": true
      },
      {
        "text": "Neural Networks",
        "isCorrect": false
      },
      {
        "text": "Genetic Algorithms",
        "isCorrect": false
      }
    ]
  },
  {
    "text": "The term 'Artificial Intelligence' was first coined by",
    "options": [
      {
        "text": "John McCarthy",
        "isCorrect": true
      },
      {
        "text": "Alan Turing",
        "isCorrect": false
      },
      {
        "text": "Marvin Minsky",
        "isCorrect": false
      },
      {
        "text": "Herbert Simon",
        "isCorrect": false
      }
    ]
  },
  {
    "text": "Which of the following is NOT a characteristic of state-of-the-art AI systems?",
    "options": [
      {
        "text": "Autonomous learning",
        "isCorrect": false
      },
      {
        "text": "Symbolic reasoning",
        "isCorrect": false
      },
      {
        "text": "High computational cost",
        "isCorrect": false
      },
      {
        "text": "Zero adaptability",
        "isCorrect": true
      }
    ]
  },
  {
    "text": "Which type of AI is designed to handle specific tasks and does not generalize?",
    "options": [
      {
        "text": "Artificial General Intelligence (AGI)",
        "isCorrect": false
      },
      {
        "text": "Narrow AI",
        "isCorrect": true
      },
      {
        "text": "Strong AI",
        "isCorrect": false
      },
      {
        "text": "Superintelligent AI",
        "isCorrect": false
      }
    ]
  },
  {
    "text": "Artificial General Intelligence (AGI) refers to",
    "options": [
      {
        "text": "AI that can perform any intellectual task that a human can do",
        "isCorrect": true
      },
      {
        "text": "AI specialized in only one task",
        "isCorrect": false
      },
      {
        "text": "AI that surpasses human intelligence",
        "isCorrect": false
      },
      {
        "text": "AI that operates in real-time",
        "isCorrect": false
      }
    ]
  },
  {
    "text": "Superintelligent AI refers to",
    "options": [
      {
        "text": "AI that can only perform predefined tasks",
        "isCorrect": false
      },
      {
        "text": "AI that surpasses human intelligence in all aspects",
        "isCorrect": true
      },
      {
        "text": "AI that can perform medical tasks only",
        "isCorrect": false
      },
      {
        "text": "AI that works in specific environments",
        "isCorrect": false
      }
    ]
  },
  {
    "text": "An intelligent agent is defined as a system that",
    "options": [
      {
        "text": "Always behaves randomly",
        "isCorrect": false
      },
      {
        "text": "Acts rationally in a given environment",
        "isCorrect": true
      },
      {
        "text": "Only processes data passively",
        "isCorrect": false
      },
      {
        "text": "Requires human intervention for every action",
        "isCorrect": false
      }
    ]
  },
  {
    "text": "Which component of an intelligent agent is responsible for decision-making?",
    "options": [
      {
        "text": "Sensor",
        "isCorrect": false
      },
      {
        "text": "Actuator",
        "isCorrect": false
      },
      {
        "text": "Performance measure",
        "isCorrect": false
      },
      {
        "text": "Agent function",
        "isCorrect": true
      }
    ]
  },
  {
    "text": "An agent’s behavior is governed by its",
    "options": [
      {
        "text": "Sensors",
        "isCorrect": false
      },
      {
        "text": "Performance measure",
        "isCorrect": false
      },
      {
        "text": "Percept sequence",
        "isCorrect": true
      },
      {
        "text": "Actuators",
        "isCorrect": false
      }
    ]
  },
  {
    "text": "What role do actuators play in an intelligent agent?",
    "options": [
      {
        "text": "Sensing the environment",
        "isCorrect": false
      },
      {
        "text": "Storing knowledge",
        "isCorrect": false
      },
      {
        "text": "Executing actions",
        "isCorrect": true
      },
      {
        "text": "Learning from data",
        "isCorrect": false
      }
    ]
  },
  {
    "text": "Which of the following is a characteristic of a dynamic environment?",
    "options": [
      {
        "text": "The environment does not change while the agent is making a decision.",
        "isCorrect": false
      },
      {
        "text": "The environment changes over time regardless of the agent's actions.",
        "isCorrect": true
      },
      {
        "text": "The agent has complete knowledge of the environment.",
        "isCorrect": false
      },
      {
        "text": "The environment is fully observable.",
        "isCorrect": false
      }
    ]
  },
  {
    "text": "An environment in which the agent’s sensors give it access to the complete state of the environment is called",
    "options": [
      {
        "text": "Partially observable",
        "isCorrect": false
      },
      {
        "text": "Deterministic",
        "isCorrect": false
      },
      {
        "text": "Fully observable",
        "isCorrect": true
      },
      {
        "text": "Episodic",
        "isCorrect": false
      }
    ]
  },
  {
    "text": "In which type of environment are the outcomes of actions uncertain?",
    "options": [
      {
        "text": "Deterministic",
        "isCorrect": false
      },
      {
        "text": "Stochastic",
        "isCorrect": true
      },
      {
        "text": "Static",
        "isCorrect": false
      },
      {
        "text": "Discrete",
        "isCorrect": false
      }
    ]
  },
  {
    "text": "In problem-solving, the process of searching refers to",
    "options": [
      {
        "text": "Finding a sequence of actions leading to the goal state",
        "isCorrect": true
      },
      {
        "text": "Randomly selecting actions",
        "isCorrect": false
      },
      {
        "text": "Optimizing resource allocation",
        "isCorrect": false
      },
      {
        "text": "Avoiding the exploration of state space",
        "isCorrect": false
      }
    ]
  },
  {
    "text": "Which search method expands the shallowest unexpanded node first?",
    "options": [
      {
        "text": "Depth-first search",
        "isCorrect": false
      },
      {
        "text": "Breadth-first search",
        "isCorrect": true
      },
      {
        "text": "Uniform-cost search",
        "isCorrect": false
      },
      {
        "text": "A* search",
        "isCorrect": false
      }
    ]
  },
  {
    "text": "Depth-limited search prevents",
    "options": [
      {
        "text": "Infinite loops by limiting the depth of the search",
        "isCorrect": true
      },
      {
        "text": "Over-expansion of nodes",
        "isCorrect": false
      },
      {
        "text": "The use of a heuristic function",
        "isCorrect": false
      },
      {
        "text": "Re-exploration of states",
        "isCorrect": false
      }
    ]
  },
  {
    "text": "The A* search algorithm is both",
    "options": [
      {
        "text": "Complete and optimal",
        "isCorrect": true
      },
      {
        "text": "Incomplete and suboptimal",
        "isCorrect": false
      },
      {
        "text": "Complete but not optimal",
        "isCorrect": false
      },
      {
        "text": "Optimal but incomplete",
        "isCorrect": false
      }
    ]
  },
  {
    "text": "Which of the following is a feature of the hill-climbing search?",
    "options": [
      {
        "text": "It can get stuck in local maxima",
        "isCorrect": true
      },
      {
        "text": "It guarantees finding the global maximum",
        "isCorrect": false
      },
      {
        "text": "It explores the entire search space",
        "isCorrect": false
      },
      {
        "text": "It avoids using any heuristic function",
        "isCorrect": false
      }
    ]
  },
  {
    "text": "Simulated annealing avoids getting stuck in local maxima by",
    "options": [
      {
        "text": "Allowing occasional moves to worse states",
        "isCorrect": true
      },
      {
        "text": "Expanding all possible nodes",
        "isCorrect": false
      },
      {
        "text": "Using a heuristic to guide the search",
        "isCorrect": false
      },
      {
        "text": "Limiting the depth of search",
        "isCorrect": false
      }
    ]
  },
  {
    "text": "Uniform-cost search is optimal when",
    "options": [
      {
        "text": "All step costs are equal",
        "isCorrect": true
      },
      {
        "text": "The path cost is considered",
        "isCorrect": false
      },
      {
        "text": "The heuristic function is admissible",
        "isCorrect": false
      },
      {
        "text": "The search space is small",
        "isCorrect": false
      }
    ]
  },
  {
    "text": "In adversarial search, a game tree represents",
    "options": [
      {
        "text": "All possible states in a game",
        "isCorrect": true
      },
      {
        "text": "The optimal strategy for one player",
        "isCorrect": false
      },
      {
        "text": "A single move in a game",
        "isCorrect": false
      },
      {
        "text": "Random events in a game",
        "isCorrect": false
      }
    ]
  },
  {
    "text": "The Minimax algorithm is used in",
    "options": [
      {
        "text": "Randomized search problems",
        "isCorrect": false
      },
      {
        "text": "Single-player games",
        "isCorrect": false
      },
      {
        "text": "Two-player zero-sum games",
        "isCorrect": true
      },
      {
        "text": "Multi-agent cooperation",
        "isCorrect": false
      }
    ]
  },
  {
    "text": "In the Minimax algorithm, the 'min' player aims to",
    "options": [
      {
        "text": "Maximize the score",
        "isCorrect": false
      },
      {
        "text": "Minimize the opponent's score",
        "isCorrect": false
      },
      {
        "text": "Minimize the evaluation function",
        "isCorrect": true
      },
      {
        "text": "Randomly choose moves",
        "isCorrect": false
      }
    ]
  },
  {
    "text": "Which of the following is a limitation of the Minimax algorithm?",
    "options": [
      {
        "text": "It cannot handle games with more than two players",
        "isCorrect": false
      },
      {
        "text": "It always leads to the optimal solution",
        "isCorrect": false
      },
      {
        "text": "It assumes perfect play from both players",
        "isCorrect": true
      },
      {
        "text": "It cannot be used for turn-based games",
        "isCorrect": false
      }
    ]
  },
  {
    "text": "In a Tic-Tac-Toe game, the game ends in a draw when",
    "options": [
      {
        "text": "One player wins",
        "isCorrect": false
      },
      {
        "text": "All positions are filled without a winner",
        "isCorrect": true
      },
      {
        "text": "Both players have one move left",
        "isCorrect": false
      },
      {
        "text": "One player quits the game",
        "isCorrect": false
      }
    ]
  },
  {
    "text": "The optimal strategy for Tic-Tac-Toe ensures that",
    "options": [
      {
        "text": "The first player always wins",
        "isCorrect": false
      },
      {
        "text": "The game never ends in a draw",
        "isCorrect": false
      },
      {
        "text": "Neither player loses if they play perfectly",
        "isCorrect": true
      },
      {
        "text": "The second player always wins",
        "isCorrect": false
      }
    ]
  },
  {
    "text": "Which algorithm is commonly used to evaluate the best move in Tic-Tac-Toe?",
    "options": [
      {
        "text": "Genetic algorithm",
        "isCorrect": false
      },
      {
        "text": "Minimax algorithm",
        "isCorrect": true
      },
      {
        "text": "Breadth-first search",
        "isCorrect": false
      },
      {
        "text": "Hill-climbing",
        "isCorrect": false
      }
    ]
  },
  {
    "text": "Alpha-Beta pruning is used to",
    "options": [
      {
        "text": "Increase the depth of the Minimax search",
        "isCorrect": false
      },
      {
        "text": "Reduce the number of nodes evaluated in the Minimax algorithm",
        "isCorrect": true
      },
      {
        "text": "Guarantee a win in zero-sum games",
        "isCorrect": false
      },
      {
        "text": "Optimize random game strategies",
        "isCorrect": false
      }
    ]
  },
  {
    "text": "In Alpha-Beta pruning, the value of alpha represents",
    "options": [
      {
        "text": "The minimum score that the maximizing player is assured of",
        "isCorrect": true
      },
      {
        "text": "The maximum score that the minimizing player is assured of",
        "isCorrect": false
      },
      {
        "text": "The best move for the minimizing player",
        "isCorrect": false
      },
      {
        "text": "A random value used for evaluation",
        "isCorrect": false
      }
    ]
  },
  {
    "text": "When does Alpha-Beta pruning prune a branch in the game tree?",
    "options": [
      {
        "text": "When the branch leads to a win for the maximizing player",
        "isCorrect": false
      },
      {
        "text": "When the branch leads to a loss for the minimizing player",
        "isCorrect": false
      },
      {
        "text": "When the branch cannot affect the final decision",
        "isCorrect": true
      },
      {
        "text": "When the branch has more nodes than the rest of the tree",
        "isCorrect": false
      }
    ]
  },
  {
    "text": "Which of the following is a fundamental concept of propositional logic?",
    "options": [
      {
        "text": "Quantifiers",
        "isCorrect": false
      },
      {
        "text": "Atomic propositions",
        "isCorrect": true
      },
      {
        "text": "Unification",
        "isCorrect": false
      },
      {
        "text": "First-order predicates",
        "isCorrect": false
      }
    ]
  },
  {
    "text": "Propositional logic is also known as",
    "options": [
      {
        "text": "First-order logic",
        "isCorrect": false
      },
      {
        "text": "Predicate logic",
        "isCorrect": false
      },
      {
        "text": "Boolean logic",
        "isCorrect": true
      },
      {
        "text": "Modal logic",
        "isCorrect": false
      }
    ]
  },
  {
    "text": "In logic, a statement that is always true is called a",
    "options": [
      {
        "text": "Contradiction",
        "isCorrect": false
      },
      {
        "text": "Contingency",
        "isCorrect": false
      },
      {
        "text": "Tautology",
        "isCorrect": true
      },
      {
        "text": "Hypothesis",
        "isCorrect": false
      }
    ]
  },
  {
    "text": "Which of the following is a valid propositional logic expression?",
    "options": [
      {
        "text": "P AND Q",
        "isCorrect": true
      },
      {
        "text": "P OR",
        "isCorrect": false
      },
      {
        "text": "NOT AND Q",
        "isCorrect": false
      },
      {
        "text": "P XOR",
        "isCorrect": false
      }
    ]
  },
  {
    "text": "The truth table for a logical expression shows",
    "options": [
      {
        "text": "The possible truth values of the expression",
        "isCorrect": true
      },
      {
        "text": "The syntax of the expression",
        "isCorrect": false
      },
      {
        "text": "The predicates used in the expression",
        "isCorrect": false
      },
      {
        "text": "The quantifiers of the expression",
        "isCorrect": false
      }
    ]
  },
  {
    "text": "In AI, uncertainty is often quantified using",
    "options": [
      {
        "text": "Logic gates",
        "isCorrect": false
      },
      {
        "text": "Probabilities",
        "isCorrect": true
      },
      {
        "text": "Truth tables",
        "isCorrect": false
      },
      {
        "text": "Algorithms",
        "isCorrect": false
      }
    ]
  },
  {
    "text": "Bayes' Rule is used to",
    "options": [
      {
        "text": "Infer the likelihood of a hypothesis given observed evidence",
        "isCorrect": true
      },
      {
        "text": "Determine the optimal strategy in a game",
        "isCorrect": false
      },
      {
        "text": "Solve linear equations",
        "isCorrect": false
      },
      {
        "text": "Simplify logical expressions",
        "isCorrect": false
      }
    ]
  },
  {
    "text": "A node in a Bayesian Network represents",
    "options": [
      {
        "text": "A state in a game tree",
        "isCorrect": false
      },
      {
        "text": "A proposition in propositional logic",
        "isCorrect": false
      },
      {
        "text": "A random variable",
        "isCorrect": true
      },
      {
        "text": "An action in a search algorithm",
        "isCorrect": false
      }
    ]
  },
  {
    "text": "In first-order logic, resolution is a technique used for",
    "options": [
      {
        "text": "Proving the truth of a logic statement",
        "isCorrect": true
      },
      {
        "text": "Unifying different predicates",
        "isCorrect": false
      },
      {
        "text": "Simplifying quantifiers",
        "isCorrect": false
      },
      {
        "text": "Constructing a game tree",
        "isCorrect": false
      }
    ]
  },
  {
    "text": "Backward chaining is typically used in",
    "options": [
      {
        "text": "Propositional logic",
        "isCorrect": false
      },
      {
        "text": "First-order logic",
        "isCorrect": false
      },
      {
        "text": "Game theory",
        "isCorrect": false
      },
      {
        "text": "Logic programming",
        "isCorrect": true
      }
    ]
  },
  {
    "text": "Classical planning assumes that",
    "options": [
      {
        "text": "The environment is fully observable and deterministic",
        "isCorrect": true
      },
      {
        "text": "The environment is partially observable and stochastic",
        "isCorrect": false
      },
      {
        "text": "The environment is unpredictable",
        "isCorrect": false
      },
      {
        "text": "The environment is multi-agent and competitive",
        "isCorrect": false
      }
    ]
  },
  {
    "text": "In classical planning, the goal state is",
    "options": [
      {
        "text": "A state that maximizes utility",
        "isCorrect": false
      },
      {
        "text": "A state where a specific set of conditions is met",
        "isCorrect": true
      },
      {
        "text": "A state that minimizes cost",
        "isCorrect": false
      },
      {
        "text": "A randomly chosen state",
        "isCorrect": false
      }
    ]
  },
  {
    "text": "Planning as state-space search involves",
    "options": [
      {
        "text": "Searching through possible actions to find a sequence that leads to the goal",
        "isCorrect": true
      },
      {
        "text": "Using heuristics to estimate the best action",
        "isCorrect": false
      },
      {
        "text": "Randomly selecting actions until the goal is reached",
        "isCorrect": false
      },
      {
        "text": "Searching for the optimal policy in a probabilistic environment",
        "isCorrect": false
      }
    ]
  },
  {
    "text": "The state-space in classical planning is typically",
    "options": [
      {
        "text": "Infinite and unbounded",
        "isCorrect": false
      },
      {
        "text": "Finite and discrete",
        "isCorrect": true
      },
      {
        "text": "Randomly generated",
        "isCorrect": false
      },
      {
        "text": "Continuous and stochastic",
        "isCorrect": false
      }
    ]
  },
  {
    "text": "Forward search in planning starts from",
    "options": [
      {
        "text": "The goal state and works backward",
        "isCorrect": false
      },
      {
        "text": "An arbitrary state in the search space",
        "isCorrect": false
      },
      {
        "text": "The initial state and moves towards the goal state",
        "isCorrect": true
      },
      {
        "text": "The most promising node in the search space",
        "isCorrect": false
      }
    ]
  },
  {
    "text": "In forward search, the successor function",
    "options": [
      {
        "text": "Generates the next state by applying an action",
        "isCorrect": true
      },
      {
        "text": "Determines the probability of reaching the goal",
        "isCorrect": false
      },
      {
        "text": "Heuristically evaluates the current state",
        "isCorrect": false
      },
      {
        "text": "Predicts future states using a model",
        "isCorrect": false
      }
    ]
  },
  {
    "text": "Backward search in planning involves",
    "options": [
      {
        "text": "Starting from the initial state and exploring all possible actions",
        "isCorrect": false
      },
      {
        "text": "Starting from the goal state and working back to the initial state",
        "isCorrect": true
      },
      {
        "text": "Randomly selecting actions until the goal is reached",
        "isCorrect": false
      },
      {
        "text": "Using heuristics to estimate the cost of actions",
        "isCorrect": false
      }
    ]
  },
  {
    "text": "Backward search is typically used when",
    "options": [
      {
        "text": "The initial state is not known",
        "isCorrect": false
      },
      {
        "text": "The goal state is partially observable",
        "isCorrect": false
      },
      {
        "text": "The goal state is explicitly defined",
        "isCorrect": true
      },
      {
        "text": "The state space is infinite",
        "isCorrect": false
      }
    ]
  },
  {
    "text": "A planning graph is used to",
    "options": [
      {
        "text": "Represent the entire state-space in a compact form",
        "isCorrect": true
      },
      {
        "text": "Estimate the heuristic cost of actions in planning",
        "isCorrect": false
      },
      {
        "text": "Perform probabilistic reasoning about future states",
        "isCorrect": false
      },
      {
        "text": "Represent hierarchical planning tasks",
        "isCorrect": false
      }
    ]
  },
  {
    "text": "In a planning graph, mutex (mutual exclusion) relationships help to",
    "options": [
      {
        "text": "Identify actions that cannot be executed simultaneously",
        "isCorrect": true
      },
      {
        "text": "Estimate the probability of success for a plan",
        "isCorrect": false
      },
      {
        "text": "Simplify the state-space by removing redundant states",
        "isCorrect": false
      },
      {
        "text": "Generate plans in non-deterministic environments",
        "isCorrect": false
      }
    ]
  }
]
